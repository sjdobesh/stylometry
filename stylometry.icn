#------------------------------------#
# Stylometric Analysis               #
# Author: Samuel Dobesh              #
# Class: CSCI 512, Meehan            #
# Date: Feb, 2021                    #
# Desc: Process a piece of text and  #
#       produce a stats, words, and  #
#       oddwords analysis files      #
#------------------------------------#----------------------------------------80

# Links
link options # for arg processing
link lists   # for list reversing proc, lreverse()
link printf  # for formatting stats with fprintf()

# PRINT USAGE #-----------------------------------------------------------------
# error proc for options.icn to print arg errors and usage
procedure usage(err_str)
  # write error if we get one
  write(\err_str)
  write(&errout, "Error\nUsage:\n./prog4 [-d dictionary] [-f file]\n")
  exit(-1)
end

# VALIDATION PROCEDURE #--------------------------------------------------------
# read and validate arguments
procedure validate(arguments)
  # check number of arguments
  if not (*arguments = 0 | *arguments = 2 | *arguments = 4) then
    usage()
  # using options.icn parser
  opt_table := options(arguments,"d:f:", usage) #<=throw usage error
  if not member(opt_table, "d") then {
    opt_table["d"] := "dict"
    write("No dictionary provided, using default 'dict' if available...")
  }
  if not member(opt_table, "f") then
    write("No file provided, reading from standard in (ctrl-d to finish)...")
  # return finished table
  return opt_table
end

# NAME EXTRACTION PROCEDURE #---------------------------------------------------
# get name of input file from a file path, minus any file extensions
procedure extract_name(file_path)
  # get the portion of string after the last "/"
  file_path ? {
    while tab(upto("/")) do
      tab(many("/"))
    # remove ".txt" if it's there
    return (tab(find("."))) | tab(0)
  }
end

# MAKE DICTIONARY SET #---------------------------------------------------------
# reads dict file into a set for us to query
procedure make_dictionary(input)
  dict := set()
  while (line := read(input)) do
      insert(dict, line)
  return dict
end

# PARAGRAPHS #------------------------------------------------------------------
# returns a list of paragraphs in the provided input file as strings
# delimiters = (empty line)
procedure paragraphs_list(input)
  # vars
  paragraphs := list(0) # (p)aragraph list to accumulate
  p          := ""      # string to accumulate each p into
  on_p       := 0       # flag for if current scan is part of a p
  last       := 0       # whether the last scan was part of a p

  # read in each line
  while line := read(input) do {
    # flag tells us wether this is a paragraph or not
    if *line == 0 then on_p := 0 else on_p := 1
    # if it is a paragraph, accumulate it via concatenation
    if on_p = 1 then {
      p ||:= (line ||:= ' ')
    }
    # otherwise add the entry to the paragraph list
    else if on_p = 0 & last = 1 then {
      put(paragraphs, p)
      p := ""
    }
    # keep track of last scan
    last := on_p
  }
  # check if we exited loop on a paragraph
  # if so we need to add the last one
  if on_p = 1 then {
    put(paragraphs, p)
  }
  # reverse before returning
  return lreverse(paragraphs)
end

# The following three procs, sentence_list(), phrase_list(), and word_list()
# all work in an analogous manner. While we can tab up to a valid starting char,
# we will tab up to the last valid character with many() and put() this
# substring on our list. When we are finished, return the accumulated list.

# SENTENCES #-------------------------------------------------------------------
# returns a list of sentences in the input string
# beginning  = any sequence of characters
# delimiters = '.!?'
procedure sentence_list(input)
  sentence := list(0)
  input ? {
    # sentences are allowed to start on any
    # character other than delimiters and spaces
    while tab(upto(&cset--' .!?')) do
      put(sentence, tab(many(&cset--'.!?')))
  }
  return sentence
end

# PHRASES #---------------------------------------------------------------------
# returns a list of phrases in the input string
# beginning  = 'alphabetic character' (any word)
# delimiters = '!,.?:;'

# *note that we already delimited by .!? so
# they have already been removed from the input here

procedure phrase_list(input)
  sentence := list(0)
  input ? {
    # phrases begin with words and can
    # include anything that's not a delimiter
    while tab(upto(&letters)) do
      put(sentence, tab(many(&cset--',:;')))
  }
  return sentence
end

# WORDS #-----------------------------------------------------------------------
# returns a list of words in the input string
# beginning  = 'alphabetic character'
# delimiters = ' '(space)
procedure word_list(input)
  words := list(0)
  input ? {
    # words have to start with a letter
    # but they're allowed to include or end with hyphens
    while tab(upto(&letters)) do
      put(words, tab(many(&letters++'-')))
  }
  return words
end

# ALPHA SORT #------------------------------------------------------------------
# handles alphabetical sub sort of equal frequencies
procedure alpha_sort(word_freq)
  sub_list := list(0)
  sorted_words := list(0)
  # collect sublists of equal frequency and alphabetize
  every i := 1 to *word_freq do {
    # if our list is empty, start it
    if *sub_list = 0 then
      put(sub_list, (word_freq[i][1] || " " || word_freq[i][2]))
    # if our list isn't empty and this freq is same as last, add it
    else if *sub_list > 0 & word_freq[i][2] == word_freq[i-1][2] then
      put(sub_list, (word_freq[i][1] || " " || word_freq[i][2]))
    # otherwise they are different frequencies, sort what we have and add it
    else {
      sub_list := sort(sub_list)
      every j := 1 to *sub_list do
        put(sorted_words, sub_list[j])
      # don't forget to empty the list
      sub_list := list(0)
    }
  }
  # append any remaining elements
  if (*sub_list > 0) then {
    sub_list := sort(sub_list)
    every j := 1 to *sub_list do
      put(sorted_words, sub_list[j])
  }
  # now sorted by frequency and then ascii value
  return sorted_words
end

# MAIN #========================================================================
procedure main(args)

  # SETUP #---------------------------------------------------------------------
  # read args
  arg_table := validate(args) | exit(-1)
  # open files to read in data
  dict := open(\arg_table["d"]) | stop("Error\nCouldn't open dictionary...")
  # if no file provided then read from std in instead
  if \arg_table["f"] then
    intext := open(\arg_table["f"]) | stop("Error\nCouldn't open file...")
  else
    intext := &input
  # make dictionary set
  dict    := make_dictionary(dict)
  # extract name for output files
  if \arg_table["f"] then
    x := extract_name(arg_table["f"])
  else
    x := "x"
  # concatenate new file names
  xs_name := x || "-stats.txt"
  xw_name := x || "-words.txt"
  xo_name := x || "-oddwords.txt"
  # open output files for writing
  x_stats := open(xs_name, "w") | stop("Error opening file")
  x_words := open(xw_name, "w") | stop("Error opening file")
  x_odd   := open(xo_name, "w") | stop("Error opening file")

  # ANALYZE #-------------------------------------------------------------------
  # depth first parse of tree
  # root -> paragraphs -> sentences -> phrases -> words

  # data to collect
  num_P      := 0        # Paragraphs
  num_s      := 0        # sentences
  num_p      := 0        # phrases
  num_w      := 0        # words
  P_num_c    := 0.0      # chars in Paragraphs
  s_num_c    := 0.0      # chars in sentences
  p_num_c    := 0.0      # chars in phrases
  w_num_c    := 0.0      # chars in words
  odd_chars  := 0.0      # chars in oddwords
  odd        := set()    # odd words
  word_table := table(0) # word_table

  # at each level, incriment that levels counter,
  # count chars, get list of child nodes and do the same
  paragraphs := paragraphs_list(intext)
  num_P := *paragraphs
  # for each paragraph
  every i := 1 to *paragraphs do {
    P_num_c +:= *paragraphs[i]
    sentences := sentence_list(paragraphs[i])
    # for each sentence
    every j := 1 to *sentences do {
      num_s +:= 1
      s_num_c +:= *sentences[j] + 1
      phrases := phrase_list(sentences[j])
      # for each phrase
      every k := 1 to *phrases do {
        num_p +:= 1
        p_num_c +:= *phrases[k]
        words := word_list(phrases[k])
        # for each word
        every l := 1 to *words do {
          num_w +:= 1
          w_num_c +:= *words[l]
          # add to frequency table
          word_table[words[l]]+:= 1
          # look up word and lowercase counter part in dict
          # if unfound, add it to the odd word list
          if not (member(dict, map(words[l], &ucase, &lcase)) |
                  member(dict, words[l])) then
            insert(odd, words[l])
        }
      }
    }
  }
  P_num_c -:= 1 # don't count <feff> char or end of stream
  # sort words for frequency and oddwords lexically
  word_freq := alpha_sort(lreverse(sort(word_table, 2)))
  odd := sort(odd, 4)
  # count oddword chars
  every i := 1 to *odd do
    odd_chars +:= *odd[i]
  if *odd > 0 then odd_chars := 1.0*odd_chars/*odd

  # WRITE DATA TO FILES #------------------------------------------------------
  #
  #   words    : word list with frequencies, by frequency and lexical order
  #
  #   oddwords : list of any word not present in dictionary, by lexical order
  #
  #   stats    : # of paragraphs, avg length in sentences, words, chars
  #              # of sentences,  avg length in phrases    words, chars
  #              # of phrases,    avg length in words,     chars
  #              # of words,      avg length in chars
  #              # of oddwords,   avg length in chars

  # STATS DATA #--------------------------------------------
  fprintf(x_stats, "paragraphs   %d", num_P)
  fprintf(x_stats, "\taverage length    ")
  fprintf(x_stats, "%.2r sentences\t", 1.0*num_s/num_P)
  fprintf(x_stats, "%.2r words    \t", 1.0*num_w/num_P)
  fprintf(x_stats, "%.2r characters\n", 1.0*P_num_c/num_P)
  fprintf(x_stats, "sentences    %d", num_s)
  fprintf(x_stats, "\taverage length    ")
  fprintf(x_stats, "%.2r phrases  \t", 1.0*num_p/num_s)
  fprintf(x_stats, "%.2r words    \t", 1.0*num_w/num_s)
  fprintf(x_stats, "%.2r characters\n", 1.0*s_num_c/num_s)
  fprintf(x_stats, "phrases      %d", num_p)
  fprintf(x_stats, "\taverage length    ")
  fprintf(x_stats, "%.2r words    \t", 1.0*num_w/num_p)
  fprintf(x_stats, "%.2r characters\n", 1.0*p_num_c/num_p)
  fprintf(x_stats, "words        %d", num_w)
  fprintf(x_stats, "\taverage length    ")
  fprintf(x_stats, "%.2r characters\n", 1.0*w_num_c/num_w)
  fprintf(x_stats, "oddwords     %d", *odd)
  fprintf(x_stats, "\taverage length    ")
  fprintf(x_stats, "%.2r characters\n", odd_chars)

  # ODD DATA #----------------------------------------------
  every i := 1 to *odd do
    write(x_odd, odd[i])

  # WORD DATA #---------------------------------------------
  every i := 1 to *word_freq do
    write(x_words, word_freq[i])

end

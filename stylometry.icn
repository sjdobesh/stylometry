#------------------------------------#
# Stylometric Analysis               |
# Author: Samuel Dobesh              |
# Desc: Process a piece of text and  |
#       produce a stats, words, and  |
#       oddwords analysis files      |
#------------------------------------#----------------------------------------80

# Links
link options
link lists
link printf

# PRINT USAGE #-----------------------------------------------------------------
# error proc for options.icn to print arg errors and usage
procedure usage(err_str)
  write(\err_str)
  write(&errout, "Argument Error\nUsage:\n./prog4 [-d dictionary] [-f file]\n")
  exit(-1)
end

# VALIDATION PROCEDURE #--------------------------------------------------------
# read and validate arguments
procedure validate(arguments)
  # check number of arguments
  if not (*arguments = 0 | *arguments = 2 | *arguments = 4) then {
    usage("")
  }
  # using options.icn parser
  opt_table := options(arguments,"d:f:", usage)
  if not member(opt_table, "d") then {
    opt_table["d"] := "dict"
    write("No dictionary provided, searching for default 'dict'...")
  }
  if not member(opt_table, "f") then {
    write("No file provided, reading from standard in (ctrl-d to finish)...")
  }

  return opt_table
end

# NAME EXTRACTION PROCEDURE #---------------------------------------------------
# get name of input file from a file path, minus any file extensions
procedure extract_name(file_path)
  # get the portion of string after the last "/"
  file_path ? {
    while tab(upto("/")) do
      tab(many("/"))
    # remove ".txt" if it's there
    return (tab(find("."))) | tab(0)
  }
end

# MAKE DICTIONARY SET #---------------------------------------------------------
# reads dict file into a set for us to query
procedure make_dictionary(input)
  dict := set()
  while (line := read(input)) do
      insert(dict, line)
  return dict
end

# SCAN FUNCTIONS #--------------------------------------------------------------
# The following functions scan their input for the corresponding
# unit of text and assemble these units into a list.

# PARAGRAPHS #---------------------------------------------
# delimiters = (empty line)
# note that we are concatenating each paragraph into a single string
procedure paragraphs_list(input)
  # vars
  paragraphs := list(0) # (p)aragraph list to accumulate
  p          := ""      # string to accumulate each p into
  on_p       := 0       # flag for if current scan is part of a p
  last       := 0       # whether the last scan was part of a p

  # read in each line
  while line := read(input) do {
    # flag tells us wether this is a paragraph or not
    if *line == 0 then on_p := 0 else on_p := 1
    # if it is a paragraph, accumulate it via concatenation
    if on_p = 1 then {
      p ||:= (line ||:= ' ')
    }
    # otherwise add the entry to the paragraph list
    else if on_p = 0 & last = 1 then {
      put(paragraphs, p)
      p := ""
    }
    # keep track of last scan
    last := on_p
  }
  # check if we exited loop on a paragraph
  # if so we need to add the last one
  if on_p = 1 then {
    put(paragraphs, p)
  }
  # reverse before returning
  return lreverse(paragraphs)
end

# SENTENCES #-----------------------------------------------
# beginning  = any sequence of characters
# delimiters = '.!?'
procedure sentence_list(input)
  sentence := list(0)
  input ? {
    # sentences are allowed to start on any character
    # other than what the end with and spaces
    while tab(upto(&cset--' .!?')) do
      put(sentence, tab(many(&cset--'.!?')))
  }
  return sentence
end

# PHRASES #--------------------------------------------------
# beginning  = 'alphabetic character' (any word)
# delimiters = ',;:'

# *note that we already delimited by .!? so
# they have already been removed from the input here

procedure phrase_list(input)
  sentence := list(0)
  input ? {
    while tab(upto(&letters)) do
      put(sentence, tab(many(&cset--',;:')))
  }
  return sentence
end

# WORDS #---------------------------------------------------
# beginning  = 'alphabetic character'
# delimiters = ' '(space)
procedure word_list(input)
  words := list(0)
  input ? {
    while tab(upto(&letters)) do
      put(words, tab(many(&letters++'-')))
  }
  return words
end

# ALPHA SORT #------------------------------------------------------------------
# handles alphabetical sub sort of equal frequencies
procedure alpha_sort(word_freq)
  sub_list := list(0)
  sorted_words := list(0)
  # collect sublists of equal frequency and alphabetize
  every i := 1 to *word_freq do {
    # if our list is empty, start it
    if *sub_list = 0 then
      put(sub_list, (word_freq[i][1] || " " || word_freq[i][2]))
    # if our list isn't empty and this freq is same as last, add it
    else if *sub_list > 0 & word_freq[i][2] == word_freq[i-1][2] then
      put(sub_list, (word_freq[i][1] || " " || word_freq[i][2]))
    # otherwise they are different frequencies, sort what we have and add it
    else {
      sub_list := sort(sub_list)
      every j := 1 to *sub_list do
        put(sorted_words, sub_list[j])
      # don't forget to empty the list
      sub_list := list(0)
    }
  }
  # append any remaining elements
  if (*sub_list > 0) then {
    sub_list := sort(sub_list)
    every j := 1 to *sub_list do
      put(sorted_words, sub_list[j])
  }
  return sorted_words
end

# MAIN #------------------------------------------------------------------------
procedure main(args)

  # SETUP #-------------------------------------------------
  # read args
  arg_table := validate(args) | exit(-1)
  # open files to read in data
  dict := open(\arg_table["d"]) | stop("Couldn't open dictionary")
  # if no file provided then read from std in instead
  if \arg_table["f"] then {
    intext := open(\arg_table["f"]) | stop("Couldn't open file")
  }
  else {
    intext := &input
  }
  # make dictionary set
  dict    := make_dictionary(dict)
  # extract name for output files
  if \arg_table["f"] then
    x := extract_name(arg_table["f"])
  else
    x := "x"
  # concatenate new file names
  xs_name := x || "-stats.txt"
  xw_name := x || "-words.txt"
  xo_name := x || "-oddwords.txt"
  # open output files for writing
  x_stats := open(xs_name, "w") | stop("Error opening file")
  x_words := open(xw_name, "w") | stop("Error opening file")
  x_odd   := open(xo_name, "w") | stop("Error opening file")

  # PARSE #-------------------------------------------------
  # data to collect
  num_P      := 0        # Paragraphs
  num_s      := 0        # sentences
  num_p      := 0        # phrases
  num_w      := 0        # words
  P_num_c    := 0.0      # chars in Paragraphs
  s_num_c    := 0.0      # chars in sentences
  p_num_c    := 0.0      # chars in phrases
  w_num_c    := 0.0      # chars in words
  odd_chars  := 0.0      # chars in oddwords
  odd        := set()    # odd words
  word_table := table(0) # word_table
  # depth first parse of tree
  # root -> pragraphs -> sentences -> phrases -> words
  paragraphs := paragraphs_list(intext)
  num_P := *paragraphs
  # for each paragraph
  every i := 1 to *paragraphs do {
    P_num_c +:= *paragraphs[i]
    sentences := sentence_list(paragraphs[i])
    # for each sentence
    every j := 1 to *sentences do {
      num_s +:= 1
      s_num_c +:= *sentences[j] + 1
      phrases := phrase_list(sentences[j])
      # for each phrase
      every k := 1 to *phrases do {
        num_p +:= 1
        p_num_c +:= *phrases[k]
        words := word_list(phrases[k])
        # for each word
        every l := 1 to *words do {
          num_w +:= 1
          w_num_c +:= *words[l]
          # add to frequency list
          word_table[words[l]]+:= 1
          # I don't think I can make this line less than 80 :(
          # look up word and lowercase counter part in dict
          if not (member(dict, map(words[l], &ucase, &lcase)) | member(dict, words[l])) then
            insert(odd, words[l])
        }
      }
    }
  }
  P_num_c -:= 1

  # sort words for frequency and oddwords lexically
  word_freq := alpha_sort(lreverse(sort(word_table, 2)))
  odd := sort(odd, 4)
  every i := 1 to *odd do
    odd_chars +:= *odd[i]
  if *odd > 0 then odd_chars := 1.0*odd_chars/*odd

  # WRITE DATA TO FILES #-----------------------------------
  #
  #   words    : word frequencies sorted by frequency and lexical order
  #
  #   oddwords : collect any word not present in a dictionary, lexical order
  #
  #   stats    : # of paragraphs, avg length in sentences, words, chars
  #              # of sentences, avg length in phrases words, chars
  #              # of phrases, avg length in words, chars
  #              # of words, avg length in chars
  #              # of oddwords, avg length in chars

  # STATS DATA #------------------------
  fprintf(x_stats, "paragraphs   %d", num_P)
  fprintf(x_stats, "\taverage length    ")
  fprintf(x_stats, "%.2r sentences\t", 1.0*num_s/num_P)
  fprintf(x_stats, "%.2r words    \t", 1.0*num_w/num_P)
  fprintf(x_stats, "%.2r characters\n", 1.0*P_num_c/num_P)
  fprintf(x_stats, "sentences    %d", num_s)
  fprintf(x_stats, "\taverage length    ")
  fprintf(x_stats, "%.2r phrases  \t", 1.0*num_p/num_s)
  fprintf(x_stats, "%.2r words    \t", 1.0*num_w/num_s)
  fprintf(x_stats, "%.2r characters\n", 1.0*s_num_c/num_s)
  fprintf(x_stats, "phrases      %d", num_p)
  fprintf(x_stats, "\taverage length    ")
  fprintf(x_stats, "%.2r words    \t", 1.0*num_w/num_p)
  fprintf(x_stats, "%.2r characters\n", 1.0*p_num_c/num_p)
  fprintf(x_stats, "words        %d", num_w)
  fprintf(x_stats, "\taverage length    ")
  fprintf(x_stats, "%.2r characters\n", 1.0*w_num_c/num_w)
  fprintf(x_stats, "oddwords     %d", *odd)
  fprintf(x_stats, "\taverage length    ")
  fprintf(x_stats, "%.2r characters\n", odd_chars)

  # ODD DATA #--------------------------
  every i := 1 to *odd do
    write(x_odd, odd[i])

  # WORD DATA #-------------------------
  every i := 1 to *word_freq do
    write(x_words, word_freq[i])

end

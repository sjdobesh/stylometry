#------------------------------------#
# Stylometric Analysis               |
# Author: Samuel Dobesh              |
# Desc: Process a piece of text and  |
#       produce a stats, words, and  |
#       oddwords analysis files      |
#------------------------------------#----------------------------------------80

# Links
link options
link lists

# VALIDATION PROCEDURE #--------------------------------------------------------
procedure validate(arguments)
  usage := "Argument Error\nUsage:\n./prog4 [-d dictionary] [-f file]"
  # check number of arguments
  if *arguments != 4 then {
    write(usage)
    fail
  }
  # using options.icn parser
  opt_table := options(arguments,"d:f:")
  return \opt_table
end

# NAME EXTRACTION PROCEDURE #---------------------------------------------------
procedure extract_name(file_path)
  # get the portion of string after the last "/"
  file_path ? {
    while tab(upto("/")) do
      tab(many("/"))
    # remove ".txt"
    return (tab(find(".")))
  }
end

# MAKE DICTIONARY SET #---------------------------------------------------------
procedure make_dictionary(input)
  dict := set()
  while (line := read(input)) do
      insert(dict, line)
  return dict
end

# FREQUENCY GENERATOR #---------------------------------------------------------
procedure get_words_freq(str)
  words := table(0)
  str ? {
    while tab(upto(&letters)) do
      words[tab(many(&letters))]+:=1
  }
  return words
end

# SCAN FUNCTIONS #--------------------------------------------------------------
# The following functions scan their input for the corresponding
# unit of text and assemble these units into a list.

# PARAGRAPHS #---------------------------------------------
# delimiters = (empty line)
procedure paragraphs_list(input)
  # vars
  paragraphs := list(0) # (p)aragraph list to accumulate
  p          := ""      # string to accumulate each p into
  on_p       := 0       # flag for whthe current scan is part of a p
  last       := 0       # weather the last scan was part of a p

  # read in each line
  while line := read(input) do {
    # flag tells us wether this is a paragraph or not
    if *line == 0 then on_p := 0 else on_p := 1
    # accumulate
    if on_p = 1 then {
      p ||:= (line ||:= ' ')
    }
    # add entry to the paragraph list
    else if on_p = 0 & last = 1 then {
      put(paragraphs, p)
      p := ""
    }
    # keep track of last scan
    last := on_p
  }

  # check if we exited loop on a paragraph
  if on_p = 1 then {
    put(paragraphs, p)
  }
  # reverse before returning
  return lreverse(paragraphs)
end

# SENTENCES #-----------------------------------------------
# delimiters = '.!?'
procedure sentence_list(input)
  sentence := list(0)
  input ? {
    while tab(upto(&letters)) do
      put(sentence, tab(many(',:; '++&letters)))
  }
  return sentence
end

# PHRASES #--------------------------------------------------
# delimiters = ',;:'
procedure phrase_list(input)
  sentence := list(0)
  input ? {
    while tab(upto(&letters)) do
      put(sentence, tab(many(' '++&letters)))
  }
  return sentence
end

# WORDS #---------------------------------------------------
# delimiters = ' '
procedure word_list(input)
  words := list(0)
  input ? {
    while tab(upto(&letters)) do
      put(words, tab(many(&letters)))
  }
  return words
end

# ALPHA SORT #------------------------------------------------------------------
# handles non lexical ordered alphabet sort of equal frequencies
procedure alpha_sort(word_freq)
  sub_list := list(0)
  sorted_words := list(0)
  # collects sublists of equal frequency
  every i := 1 to *word_freq do {
    if *sub_list = 0 then
      put(sub_list, (word_freq[i][1] || " " || word_freq[i][2]))
    else if *sub_list > 0 & word_freq[i][2] == word_freq[i-1][2] then
      put(sub_list, (word_freq[i][1] || " " || word_freq[i][2]))
    else {
      sub_list := sort(sub_list)
      every j := 1 to *sub_list do
        put(sorted_words, sub_list[j])
      sub_list := list(0)
    }
  }
  # append any remaining
  if (*sub_list > 0) then {
    sub_list := sort(sub_list)
    every j := 1 to *sub_list do
      put(sorted_words, sub_list[j])
  }

  return sorted_words
end

# MAIN #------------------------------------------------------------------------
procedure main(args)

  # read args
  arg_table := validate(args) | exit(-1)

  # open files to read in data
  dict    := open(\arg_table["d"]) | stop("Couldn't open dictionary")
  intext  := open(\arg_table["f"]) | stop("Couldn't open file")

  # make dictionary set
  dict    := make_dictionary(dict)

  # extract name for output files
  x := extract_name(arg_table["f"])
  write("Extracted name : ", x)

  # concatenate new file names
  xs_name := x || "-stats.txt"
  xw_name := x || "-words.txt"
  xo_name := x || "-oddwords.txt"

  # open output files for writing
  x_stats := open(xs_name, "w") | stop("Error opening file")
  x_words := open(xw_name, "w") | stop("Error opening file")
  x_odd   := open(xo_name, "w") | stop("Error opening file")

  # read in text to analyze

  # data to collect
  num_P      := 0.0      # Paragraphs
  num_s      := 0.0      # sentences
  num_p      := 0.0      # phrases
  num_w      := 0.0      # words
  P_num_c    := 0.0      # chars in Paragraphs
  s_num_c    := 0.0      # chars in sentences
  p_num_c    := 0.0      # chars in phrases
  w_num_c    := 0.0      # chars in phrases
  odd        := set()    # odd words
  word_table := table(0) # word_table

  # PARSE #-------------------------------------------------
  paragraphs := paragraphs_list(intext)
  num_P := *paragraphs
  root := list(0)
  every i := 1 to *paragraphs do {
    P_num_c +:= *paragraphs[i]
    sentences := sentence_list(paragraphs[i])
    s_layer := list(0)
    every j := 1 to *sentences do {
      num_s +:= 1
      s_num_c +:= *sentences[j] + 1
      phrases := phrase_list(sentences[j])
      p_layer := list(0)
      every k := 1 to *phrases do {
        num_p +:= 1
        p_num_c +:= *phrases[k]
        words := word_list(phrases[k])
        every l := 1 to *words do {
          num_w +:= 1
          w_num_c +:= *words[l]
          word_table[words[l]]+:= 1
          if not member(dict, map(words[l], &ucase, &lcase)) then
            insert(odd, words[l])
          # write output for check
          # write(words[l])
        }
        put(p_layer, words)
      }
      put(s_layer, p_layer)
    }
    put(root, s_layer)
  }
  P_num_c -:= 1
  # at this point root contains the whole tree

  # sort words for frequency and oddwords lexically
  odd := sort(odd, 4)
  odd_chars := 0
  every i := 1 to *odd do
    odd_chars +:= *odd[i]
  if *odd != 0 then odd_chars := odd_chars/*odd
  word_freq := alpha_sort(lreverse(sort(word_table, 2)))

  # WRITE DATA TO FILES #-----------------------------------
  # data needed:
  #   words    : word frequencies sorted by frequency and lexical order
  #   oddwords : collect any word not present in a dictionary
  #   stats    : # of paragraphs, avg length in sentences, words, chars
  #              # of sentences, avg length in phrases words, chars
  #              # of phrases, avg length in words, chars

  # print stats for inspection
  write ("\n\n\nData Collected:\n")
  writes("paragraphs :\t", num_P)
  writes("\tsentence :\t", num_s/num_P)
  writes("\twords :\t", num_w/num_P)
  write ("\tchars :\t", P_num_c)
  writes("sentences :\t", num_s)
  writes("\tphrases :\t", num_p/num_s)
  writes("\twords :\t", num_w/num_s)
  write ("\tchars :\t", s_num_c/num_s)
  writes("phrases :\t", num_p)
  writes("\twords :\t", num_w/num_p)
  write ("\tchars :\t", p_num_c/num_p)
  writes("words :\t", num_w)
  write ("\tchars :\t", w_num_c/num_w)
  writes("oddwords :\t", *odd)
  write ("\tchars :\t", odd_chars)

  # STATS DATA #------------------------
  write (x_stats, "\n\n\nData Collected:\n")
  writes(x_stats, "paragraphs :\t", num_P)
  writes(x_stats, "\tsentence :\t", num_s/num_P)
  writes(x_stats, "\twords :\t", num_w/num_P)
  write (x_stats, "\tchars :\t", P_num_c)
  writes(x_stats, "sentences :\t", num_s)
  writes(x_stats, "\tphrases :\t", num_p/num_s)
  writes(x_stats, "\twords :\t", num_w/num_s)
  write (x_stats, "\tchars :\t", s_num_c/num_s)
  writes(x_stats, "phrases :\t", num_p)
  writes(x_stats, "\twords :\t", num_w/num_p)
  write (x_stats, "\tchars :\t", p_num_c/num_p)
  writes(x_stats, "words :\t", num_w)
  write (x_stats, "\tchars :\t", w_num_c/num_w)
  writes(x_stats, "oddwords :\t", *odd)
  write (x_stats, "\tchars :\t", odd_chars)

  # ODD DATA #--------------------------
  write("\nOdd words\n")
  every i := 1 to *odd do
    write(x_odd, odd[i])

  # WORD DATA #-------------------------
  write("Unique words : ", *word_freq)
  every i := 1 to *word_freq do
    write(x_words, word_freq[i])
end
